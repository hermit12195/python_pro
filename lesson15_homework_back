import csv
from datetime import datetime, timedelta
import requests
import logging
import aiohttp
import pandas as pd
from bs4 import BeautifulSoup

logging.basicConfig(filename="app.log", level=logging.DEBUG)


class EmptyFileError(Exception):
    def __init__(self):
        self.message=("File is empty! Please check the parsed file content.")
        super().__init__(self.message)

async def get_page(url: str) -> tuple:
    if isinstance(url, str):
        soup=""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url) as response:
                    if response.status == 200:
                        logging.info(
                            f"{datetime.utcnow().replace(microsecond=0)} - Successfully established connection with server!")
                        soup=await response.text()
                        return (BeautifulSoup(soup, "lxml"), url)
                    else:
                        logging.error(
                            f"{datetime.datetime.utcnow().replace(microsecond=0)} - The server status response is not 200! Please check connectivity to the server.")
        except requests.ConnectionError as e:
            logging.error(f"ERROR: {e.__repr__()}")
    else:
        logging.error(
            f"{datetime.utcnow().replace(microsecond=0)} - Invalid data type! Please use type str for 'url' argument.")


async def parse_news(soup: tuple) -> list:
    if isinstance(soup, tuple):
        news_list: list = []
        if soup[1] and soup[0]:
            soup, url = soup[0], soup[1]
        else:
            logging.error(f"{datetime.utcnow().replace(microsecond=0)} - url argument is None type!")
            raise ValueError("None type error! Please check the parsed arguments.")
        try:
            news_line = soup.find_all("div", class_="news-item")
            if len(news_line) != 0:
                async with aiohttp.ClientSession() as session:
                    for div in news_line:
                        news_dict = {}
                        div_title = div.find(class_="news-title")
                        if div_title and div_title.find("a"):
                            news_title = div_title.find("a").text
                            news_link = url + div_title.find("a").get("href").lstrip("/")
                        else:
                            raise ValueError(
                                "No divs found with class 'news-title'! None type is returned! Please check the class name.")
                        async with session.get(news_link) as response:
                            res_soup=await response.text()
                            plot_soup = BeautifulSoup(res_soup, "lxml")
                            news_plot = plot_soup.find(class_="text").text.strip()
                        div_date = div.find(class_="news-date")
                        if div_date is not None:
                            news_date = div_date.text.split(", ")[0]
                        else:
                            raise ValueError(
                                "No divs found with class 'news-date'! None type is returned! Please check the class name.")
                        news_dict["title"] = news_title
                        news_dict["date"] = news_date
                        news_dict["link"] = news_link
                        news_dict["plot"] = news_plot
                        news_list.append(news_dict)
                    logging.info(f"{datetime.utcnow().replace(microsecond=0)} - Successfully parsed the news!")
                    return news_list
            else:
                raise ValueError(
                    "No divs found with class 'news-item'! None type is returned! Please check the class name.")
        except ValueError as e:
            logging.error(f"{datetime.utcnow().replace(microsecond=0)} - {e.__repr__()}")
            raise ValueError(f'{e.__repr__()}')
    else:
        logging.error(
            f"{datetime.utcnow().replace(microsecond=0)} - Invalid data type! Please use type tuple for 'soup' argument.")
        raise ValueError("Invalid data type! Please use type tuple for 'soup' argument.")


def save_to_csv(filename: str, data: list):
    if isinstance(filename, str) and isinstance(data, list):
        try:
            with open(filename, "w", encoding="UTF-8") as csvfile:
                csvwriter = csv.DictWriter(csvfile, fieldnames=["title", "link", "date", "plot"])
                csvwriter.writeheader()
                csvwriter.writerows(data)
            logging.info(
                f"{datetime.utcnow().replace(microsecond=0)} - Successfully saved the parsed data in CSV file!")
        except FileNotFoundError as e:
            logging.error(
                f"{datetime.utcnow().replace(microsecond=0)} - File not found! Please check the file name.")
            raise FileNotFoundError
    else:
        logging.error(
            f"{datetime.utcnow().replace(microsecond=0)} - Invalid data type! Please use type str for 'filename' argument and type list for 'data' argument.")
        raise ValueError("Invalid data type! Please use type str for 'filename' argument and type list for 'data' argument.")


def filter_by_date(news_list: list, days_num: int):
    if isinstance(news_list, list) and isinstance(days_num, int):
        if news_list != 0 and news_list:
            filtered_list: list = []
            for news_dict in news_list:
                if datetime.strptime(news_dict["date"], '%d.%m.%Y').date() >= datetime.utcnow().date() - timedelta(days=days_num):
                    filtered_list.append((news_dict['title'],news_dict['date'].strip()))
            return filtered_list
            logging.info("Successfully sorted news by date!")
        else:
            logging.error(
                f"{datetime.utcnow().replace(microsecond=0)} - Empty list! Please check the parsed argument with type list.")
    else:
        logging.error(
            f"{datetime.utcnow().replace(microsecond=0)} - Invalid data type! Please use type list for 'news_list' argument and int for 'days_num' argument.")


def news_number(file_name: str):
    if isinstance(file_name, str):
        try:
            df = pd.read_csv(file_name)
            return df.groupby(df["date"]).size()
        except pd.errors.EmptyDataError as e:
            logging.error(f"{datetime.utcnow().replace(microsecond=0)} - {e.__repr__()}")
            raise EmptyFileError
    else:
        logging.error(
            f"{datetime.utcnow().replace(microsecond=0)} - Invalid data type! Please use type str for 'file_name' argument.")
